<h1 align="center">ComparaÃ§Ã£o de MÃ©tricas de DistÃ¢ncia no KNN</h1>

<p align="center">
Este repositÃ³rio tem como objetivo <strong>analisar e comparar diferentes mÃ©tricas de distÃ¢ncia</strong> aplicadas ao classificador  
<strong>K-Nearest Neighbors (KNN)</strong>.  
Projeto acadÃªmico voltado para <strong>Reconhecimento de PadrÃµes</strong>, explorando o impacto das mÃ©tricas
no desempenho do classificador.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/status-concluÃ­do-brightgreen" alt="Status">
  <img src="https://img.shields.io/badge/linguagem-Java-blue" alt="Linguagem">
  <img src="https://img.shields.io/badge/classificador-KNN-orange" alt="KNN">
</p>

> **Ãrea:** Aprendizado de MÃ¡quina / InteligÃªncia Artificial  
> **Algoritmo:** K-Nearest Neighbors (KNN)  
> **Foco:** ComparaÃ§Ã£o de mÃ©tricas de distÃ¢ncia

---

## ğŸ“˜ DescriÃ§Ã£o

O **K-Nearest Neighbors (KNN)** Ã© um classificador baseado em instÃ¢ncias, que nÃ£o realiza treinamento explÃ­cito.
A classificaÃ§Ã£o de uma nova amostra ocorre a partir da anÃ¡lise das **K amostras mais prÃ³ximas** no conjunto de treino,
de acordo com uma **mÃ©trica de distÃ¢ncia**.

Este projeto tem como objetivo **comparar o impacto de diferentes mÃ©tricas de distÃ¢ncia**
no desempenho do KNN, avaliando acurÃ¡cia, comportamento prÃ³ximo Ã  fronteira de decisÃ£o
e sensibilidade ao valor de **K**.

---

## âš™ï¸ O Algoritmo KNN (visÃ£o geral)

1. Calcula a distÃ¢ncia entre a amostra de teste e todas as amostras de treino.
2. Seleciona os **K vizinhos mais prÃ³ximos**.
3. Realiza uma **votaÃ§Ã£o majoritÃ¡ria** entre as classes.
4. Atribui Ã  amostra a classe mais frequente.

---

## ğŸ“ MÃ©tricas de DistÃ¢ncia Comparadas

As mÃ©tricas de distÃ¢ncia influenciam diretamente o comportamento do KNN.  
Abaixo estÃ£o as principais utilizadas neste estudo.

---

### ğŸ”¹ DistÃ¢ncia Euclidiana

A mÃ©trica mais comum, mede a distÃ¢ncia "reta" entre dois pontos:

$$
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
$$

âœ”ï¸ Boa para dados contÃ­nuos e escalonados.  
âŒ SensÃ­vel a atributos em diferentes escalas.

---

### ğŸ”¹ DistÃ¢ncia Manhattan

Baseia-se na soma das diferenÃ§as absolutas:

$$
d(x, y) = \sum_{i=1}^{n} |x_i - y_i|
$$

âœ”ï¸ Mais robusta a outliers do que a Euclidiana.  
âŒ Pode distorcer distÃ¢ncias em espaÃ§os de alta dimensÃ£o.

---

### ğŸ”¹ DistÃ¢ncia de Minkowski

Generaliza as anteriores, controlada por um parÃ¢metro \( p \):

$$
d(x, y) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{1/p}
$$

- \( p = 1 \) â†’ Manhattan
- \( p = 2 \) â†’ Euclidiana

âœ”ï¸ Permite ajustar a sensibilidade da mÃ©trica.  
âŒ Requer escolha adequada do parÃ¢metro \( p \).

---

### ğŸ”¹ DistÃ¢ncia de Chebyshev

Considera apenas a **maior diferenÃ§a** entre os atributos:

$$
d(x, y) = \max_i |x_i - y_i|
$$

âœ”ï¸ Ãštil em casos onde o maior desvio domina a decisÃ£o.  
âŒ Pode ignorar pequenas variaÃ§Ãµes entre dimensÃµes.

---

## ğŸ“Š Base de Dados Utilizada

Foi utilizada a base **transfusion.data**, relacionada a doadores de sangue,
a mesma empregada em experimentos anteriores com **classificadores bayesianos**,
garantindo consistÃªncia experimental.

| Atributo      | DescriÃ§Ã£o                               |
| ------------- | --------------------------------------- |
| Recency (R)   | Meses desde a Ãºltima doaÃ§Ã£o             |
| Frequency (F) | NÃºmero total de doaÃ§Ãµes                 |
| Monetary (M)  | Volume total de sangue doado            |
| Time (T)      | Meses desde a primeira doaÃ§Ã£o           |
| Class         | DoaÃ§Ã£o em marÃ§o/2007 (1 = sim, 0 = nÃ£o) |

---

## ğŸ§  Etapas do Experimento

1. NormalizaÃ§Ã£o dos atributos.
2. DefiniÃ§Ã£o do valor de **K**.
3. AplicaÃ§Ã£o das mÃ©tricas de distÃ¢ncia.
4. AvaliaÃ§Ã£o por **taxa de acerto** e **matriz de confusÃ£o**.
5. ComparaÃ§Ã£o dos resultados obtidos.

---

## ğŸ“ˆ Resultados Esperados

A comparaÃ§Ã£o busca observar:

- VariaÃ§Ã£o na **acurÃ¡cia** conforme a mÃ©trica.
- DiferenÃ§as no comportamento do classificador para dados prÃ³ximos da fronteira de decisÃ£o.
- Impacto do **valor de K** no desempenho.

---

## ğŸ’» Requisitos

âœ” **Java JDK 17+**  
âœ” **Biblioteca Swing (para seleÃ§Ã£o de arquivos)**  
âœ” **Arquivos `.data` de treino e teste**

---

## ğŸš€ Uso

1ï¸âƒ£ Compile o projeto:

```bash
javac *.java
```

---

## ğŸ› ï¸ Desenvolvimento

- Projeto desenvolvido para fins acadÃªmicos.
- CÃ³digo modular, permitindo fÃ¡cil inclusÃ£o de novas mÃ©tricas.
- Estrutura compatÃ­vel com ambientes educacionais e laboratoriais.

---

## âœ… Status do Projeto

ConcluÃ­do para a disciplina de **Reconhecimento de PadrÃµes**, com possibilidade de  
extensÃ£o para novos classificadores ou mÃ©tricas adicionais.

---

## ğŸ—º Roadmap (possÃ­veis melhorias)

- [ ] ValidaÃ§Ã£o cruzada (k-fold)
- [ ] ComparaÃ§Ã£o com outros classificadores
- [ ] VisualizaÃ§Ã£o grÃ¡fica das fronteiras de decisÃ£o
- [ ] AutomatizaÃ§Ã£o da escolha do melhor valor de K
