<h1 align="center">ğŸ“Š Estimadores de Probabilidade</h1>

<p align="center">
RepositÃ³rio acadÃªmico dedicado ao estudo e implementaÃ§Ã£o de  
<strong>estimadores de densidade de probabilidade</strong>, utilizados como base
para modelos estatÃ­sticos e classificadores probabilÃ­sticos.
</p>

<p align="center">
  <img src= "https://img.shields.io/badge/tema-Estimadores%20de%20Probabilidade-purple">  
  <img src= "https://img.shields.io/badge/finalidade-acadÃªmica-blue">  
  <img src= "https://img.shields.io/badge/linguagem-Java-orange">  
</p>

> **Disciplina:** Reconhecimento de PadrÃµes  
> **Tema especÃ­fico:** Estimadores de Probabilidade  
> **Finalidade:** Estudo, experimentaÃ§Ã£o e portfÃ³lio acadÃªmico

---

## ğŸ“Œ DescriÃ§Ã£o


Este projeto tem como foco o estudo de **Estimadores de Probabilidade**, abordando
tÃ©cnicas paramÃ©tricas e nÃ£o paramÃ©tricas para modelar a distribuiÃ§Ã£o dos dados.

Os estimadores implementados sÃ£o utilizados para calcular a probabilidade de
ocorrÃªncia de valores e para apoiar decisÃµes em **modelos estatÃ­sticos
probabilÃ­sticos**, como o classificador Bayesiano.

O trabalho possui carÃ¡ter **didÃ¡tico e conceitual**, sendo desenvolvido no
contexto acadÃªmico da disciplina.

---

### ğŸ“Š Estimadores de Densidade ProbabilÃ­stica

Estimadores de densidade sÃ£o mÃ©todos estatÃ­sticos utilizados para **aproximar a
funÃ§Ã£o densidade de probabilidade** de uma variÃ¡vel aleatÃ³ria a partir de um
conjunto de amostras.

#### ğŸ”¹ Estimador Gaussiano

O **Estimador Gaussiano** Ã© um mÃ©todo **paramÃ©trico**, que assume que os dados seguem
uma **distribuiÃ§Ã£o normal**.

A densidade Ã© calculada a partir da mÃ©dia e do desvio padrÃ£o:

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \cdot e^{-\frac{(x - \mu)^2}{2\sigma^2}}
$$

Onde:

- <code>x</code> = valor da amostra
- <code>&mu;</code> = mÃ©dia da amostra
- <code>&sigma;</code> = desvio padrÃ£o da amostra

âœ”ï¸ **Vantagens:** rÃ¡pido e simples.  
âŒ **LimitaÃ§Ã£o:** funciona bem apenas se os dados forem aproximadamente normais.

---

#### ğŸ”¹ Kernel Density Estimation (KDE)


O **Kernel Density Estimation (KDE)** Ã© um mÃ©todo **nÃ£o paramÃ©trico** que nÃ£o assume
uma forma prÃ©via para a distribuiÃ§Ã£o dos dados.

A densidade Ã© estimada pela soma das contribuiÃ§Ãµes de cada ponto da amostra:

$$
\hat{f}(x) = \frac{1}{n h} \sum_{i=1}^{n} K\left(\frac{x - x_i}{h}\right)
$$

Para o **kernel Gaussiano**:

$$
K(u) = \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}}
$$

Logo, a densidade KDE fica:

$$
\hat{f}(x) = \frac{1}{n h \sqrt{2\pi}} \sum_{i=1}^{n} e^{-\frac{1}{2}\left(\frac{x - x_i}{h}\right)^2}
$$

Onde:

- <code>n</code> = nÃºmero de amostras
- <code>h</code> = largura de banda (_bandwidth_)
- <code>x<sub>i</sub></code> = cada ponto da amostra
- <code>K</code> = funÃ§Ã£o kernel

âœ”ï¸ **Vantagens:** captura distribuiÃ§Ãµes complexas.  
âŒ **LimitaÃ§Ã£o:** mais custoso computacionalmente e depende da escolha de <code>h</code>.

---

### ğŸ“Œ Classificador Bayesiano

s estimadores de densidade sÃ£o empregados como base para o cÃ¡lculo da
**verossimilhanÃ§a** em classificadores probabilÃ­sticos, como o modelo Bayesiano.

---

#### ğŸ“ Teorema de Bayes

O **Teorema de Bayes** permite atualizar a probabilidade de uma classe `C` dado um
conjunto de atributos `X`:

$$
P(C|X) = \frac{P(X|C) \cdot P(C)}{P(X)}
$$

- **P(C)** â†’ Probabilidade a priori da classe (frequÃªncia no treino).
- **P(X|C)** â†’ Probabilidade da amostra dado a classe (estimada com Gaussiana ou KDE).
- **P(X)** â†’ Constante de normalizaÃ§Ã£o (mesma para todas as classes).

---

#### âš™ï¸ Naive Bayes

O modelo **Naive Bayes** assume independÃªncia estatÃ­stica entre os atributos:

$$
P(X|C) = \prod_{i=1}^{n} P(X_i | C)
$$

Logo:

$$
P(C|X) \propto P(C) \cdot \prod_{i=1}^{n} P(X_i | C)
$$

ğŸ“Œ A classe escolhida Ã© aquela que maximiza <code>P(C|X)</code>.

âœ”ï¸ FÃ¡cil de implementar.  
âœ”ï¸ Funciona bem mesmo em cenÃ¡rios simples.  
âŒ Pode perder precisÃ£o quando os atributos sÃ£o fortemente correlacionados.

---

## ğŸ“Œ Estrutura da Base de Dados utilizada

A base de dados **transfusion.data** Ã© um conjunto de dados utilizado para prever se um doador de sangue irÃ¡ doar novamente em um determinado perÃ­odo. Ela contÃ©m informaÃ§Ãµes sobre doadores de sangue do centro de transfusÃ£o de Hsin-Chu City, Taiwan.

O conjunto de dados possui **748 registros** e **5 atributos**:

| Atributo          | DescriÃ§Ã£o                                                                                              |
| ----------------- | ------------------------------------------------------------------------------------------------------ |
| **Recency (R)**   | NÃºmero de meses desde a Ãºltima doaÃ§Ã£o.                                                                 |
| **Frequency (F)** | NÃºmero total de doaÃ§Ãµes realizadas.                                                                    |
| **Monetary (M)**  | Volume total de sangue doado em centÃ­metros cÃºbicos (c.c.).                                            |
| **Time (T)**      | NÃºmero de meses desde a primeira doaÃ§Ã£o.                                                               |
| **Class**         | VariÃ¡vel alvo binÃ¡ria que indica se o doador fez uma doaÃ§Ã£o em marÃ§o de 2007 (1 = doou, 0 = nÃ£o doou). |

âš ï¸ A distribuiÃ§Ã£o das classes Ã© **desequilibrada**, com aproximadamente 76% dos doadores **nÃ£o realizando a doaÃ§Ã£o** em marÃ§o de 2007.

---

## ğŸ“Œ Exemplos de ImplementaÃ§Ã£o

ğŸ”¹ **Gaussiana** â†’ estimativa paramÃ©trica (usa mÃ©dia e desvio).  
ğŸ”¹ **KDE** â†’ estimativa nÃ£o paramÃ©trica (usa todos os pontos do treino).  
ğŸ”¹ **Naive Bayes** â†’ classificador que combina os estimadores para prever a classe mais provÃ¡vel.

